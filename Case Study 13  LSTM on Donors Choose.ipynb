{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "LSTM donors choose.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbpkachPLgZn"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# keras import\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.datasets import imdb\n",
        "# from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import concatenate, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from datetime import time\n",
        "\n",
        "\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import LSTM, Dropout, Input, Conv1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import he_normal\n",
        "# fix random seed for reproducibility\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(7)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim import corpora\n",
        "import pickle\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Jd73BfLzwS",
        "outputId": "fa70e041-c628-486b-893a-8b7dbf062962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gNDEqd_LgZu",
        "outputId": "f21058b8-7460-43cf-f850-d145b145fd43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "df= pd.read_csv('/content/drive/My Drive/LSTM/LSTM Assignment/preprocessed_data.csv')\n",
        "df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school_state</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "      <th>essay</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>math_science</td>\n",
              "      <td>appliedsciences health_lifescience</td>\n",
              "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
              "      <td>725.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ut</td>\n",
              "      <td>ms</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
              "      <td>213.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school_state  ...   price\n",
              "0           ca  ...  725.05\n",
              "1           ut  ...  213.03\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1-3sZaBLgZy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vdRaru1LgZ1",
        "outputId": "2d9a0f25-e560-43cd-e1ae-ce253968d133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((76473, 9), (32775, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfR-B7UiLgZ4"
      },
      "source": [
        "## Text data vectorizatio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyaXBDCcLgZ5"
      },
      "source": [
        "x_train_essay_text = train_df.essay.values.tolist()\n",
        "x_test_essay_text = test_df.essay.values.tolist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS6tEXTpLgZ8",
        "outputId": "2f0e3204-ceac-4828-8a8b-b9c067e8740e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tokenizing \n",
        "# https://stackoverflow.com/questions/52126539/using-pretrained-gensim-word2vec-embedding-in-keras\n",
        "# https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train_essay_text)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(len(t.word_index))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnXuhglaTND4",
        "outputId": "0833932f-e22e-47a5-9a80-c9d165ecd611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!curl --header \"Host: storage.googleapis.com\" --header \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-US,en;q=0.9\" \"https://storage.googleapis.com/kaggle-data-sets/5504/8240/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20200929%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20200929T105817Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=741b2674fa30750d7e760462fde2c96b803c200e6351fd148cce4f6acbe1cbac45d7837e4a1ab257de4fc20b996d80254e8cc1352774738eb13aaeb8d0ad5b42ccabeb2b291d695069e336724412b5fc2e328b8036a7799aef52441c224edfd046304b4322e4fb1bfcbfbebfe0c93dd521ed3f6a7f215bcb2c13ac60e1c5df78ebeb2d2f11a9324b471f42f4266d6cf74f85772e19c514e4ea735352bf8ffc4130dbe3520250a50dccacd341c0b7c69340a199943ccbd197acdf2a21a67cfe98183bbe6ee1325347a74fea581d10c829aac7a318a292ded61d03bfb7e741cecf9a53ee4b3f0017bd9a1ed2577343bf3c065ee6b7df142bacce6040f2894fbdae\" -L -o 'archive.zip'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  386M  100  386M    0     0  49.1M      0  0:00:07  0:00:07 --:--:-- 54.1M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7kgPCk8Pl7e",
        "outputId": "527835f5-fba3-429f-fdf3-c8732824fb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip /content/archive.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/archive.zip\n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrjY8a_3LgZ_"
      },
      "source": [
        "# load embedding as a dict\n",
        "def load_embedding(filename):\n",
        "    # load embedding into memory, skip first line\n",
        "    file = open(filename, 'r')\n",
        "    lines = file.readlines()[1:] \n",
        "    file.close()\n",
        "    # create a map of words to vectors\n",
        "    embedding = dict()\n",
        "    for line in lines:\n",
        "        parts = line.split()\n",
        "        # key is string word, value is numpy array for vector\n",
        "        embedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "    return embedding\n",
        "\n",
        "# create a weight matrix for the Embedding layer from a loaded embedding\n",
        "def get_weight_matrix(embedding, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, 300))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = embedding.get(word)\n",
        "    return weight_matrix\n",
        "\n",
        "# load embedding from file\n",
        "raw_embedding = load_embedding('/content/glove.6B.300d.txt')\n",
        "\n",
        "# get vectors in the right order\n",
        "embedding_vectors = get_weight_matrix(raw_embedding, t.word_index)\n",
        "where_are_NaNs = np.isnan(embedding_vectors)\n",
        "embedding_vectors[where_are_NaNs] = 0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NpfJ9IPhpT5"
      },
      "source": [
        "with open('/content/drive/My Drive/LSTM_ASST/embedding_vectors.pickle', 'wb') as f:\n",
        "  pickle.dump([embedding_vectors], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er7w41aExR18"
      },
      "source": [
        "infile = open('/content/drive/My Drive/LSTM_ASST/embedding_vectors.pickle','rb')\n",
        "embedding_vectors = pickle.load(infile)\n",
        "infile.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrhK0GqHLgaM"
      },
      "source": [
        "#### 1 Train and Test data for text feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhCDR7plLgaM",
        "outputId": "8b0c24d9-b888-4116-c9c6-9b88758f28d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "# enocde it to sequences\n",
        "encoded_docs = t.texts_to_sequences(x_train_essay_text)\n",
        "\n",
        "# padding\n",
        "max_length = len(max(x_train_essay_text, key=len).split(' '))\n",
        "\n",
        "x_train_text = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_train_text.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPeVgD-kLgaP",
        "outputId": "319cf16e-bb38-47e0-a4e1-b7f6c18d8c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test\n",
        "# enocde it to sequences\n",
        "encoded_docs = t.texts_to_sequences(x_test_essay_text)\n",
        "x_test_text = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_test_text.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgu2lDZyLgaZ"
      },
      "source": [
        "## Categorical Featurization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NvnJA1kLgaa"
      },
      "source": [
        "**school state**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_At3Te4kLgaa",
        "outputId": "67431919-62e2-4754-c926-f07318f530d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_df.school_state.values.tolist()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWAOMhTkLgac"
      },
      "source": [
        "train_sch_state = train_df.school_state.values.tolist()\n",
        "test_sch_state = test_df.school_state.values.tolist()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjhUB-FGLgae"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sch_state)\n",
        "train_sch_state = tokenizer.texts_to_sequences(train_sch_state)\n",
        "test_sch_state = tokenizer.texts_to_sequences(test_sch_state)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkNRSQuyLgah",
        "outputId": "9eb8b858-20bb-4453-babd-8a611f94ca43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "max_length = len(max(train_sch_state, key=len))\n",
        "x_train_sch_state = sequence.pad_sequences(train_sch_state, maxlen = max_length, padding='post')\n",
        "x_train_sch_state.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpMrVwxwLgaj",
        "outputId": "e27a5ce6-66dd-4bdf-d131-a1aa3dc578e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test data\n",
        "x_test_sch_state = sequence.pad_sequences(test_sch_state, maxlen = max_length, padding='post')\n",
        "x_test_sch_state.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsHyVoGCLgal"
      },
      "source": [
        "**Project grade**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCqvGIAGLgal",
        "outputId": "c0cef380-e652-4b64-8f25-505a58406a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_df.project_grade_category.values.tolist()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GpM6hlLgao"
      },
      "source": [
        "train_df['project_grade_category'] = train_df['project_grade_category'].str.replace('_','')\n",
        "test_df['project_grade_category'] = test_df['project_grade_category'].str.replace('_','')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH3CmqS0Lgaq"
      },
      "source": [
        "train_proj_grade = train_df.project_grade_category.values.tolist()\n",
        "test_proj_grade = test_df.project_grade_category.values.tolist()\n",
        "max_length = 1 #len(max(train_proj_grade))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPL2DTAZLgas"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_proj_grade)\n",
        "train_proj_grade = tokenizer.texts_to_sequences(train_proj_grade)\n",
        "test_proj_grade = tokenizer.texts_to_sequences(test_proj_grade)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XpscdoWLgau",
        "outputId": "20850d84-24af-4c28-cb9c-92c62362f5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'grades35': 2, 'grades68': 3, 'grades912': 4, 'gradesprek2': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlJJWZpVLgaw",
        "outputId": "7829594a-9cec-4d0e-9dea-c67f0e6937be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "x_train_proj_grade = sequence.pad_sequences(train_proj_grade, maxlen = max_length, padding='post')\n",
        "x_train_proj_grade.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLR0vJioLgay",
        "outputId": "c8db2d87-1ce5-4394-91be-7fce5a391270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "x_test_proj_grade = sequence.pad_sequences(test_proj_grade, maxlen = max_length, padding='post')\n",
        "x_test_proj_grade.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2yJ4JxaLga1"
      },
      "source": [
        "**clean_cat**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqIibh79Lga1",
        "outputId": "8135068a-4221-497e-d051-af1a6b5b41b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_df.clean_categories.values.tolist()))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5lk4owKLga6"
      },
      "source": [
        "train_clean_cat = train_df.clean_categories.values.tolist()\n",
        "test_clean_cat = test_df.clean_categories.values.tolist()\n",
        "# max_length = len(max(train_clean_cat, key=len).split(' '))\n",
        "max_length = 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmwUGBRDLga8"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_clean_cat)\n",
        "train_clean_cat = tokenizer.texts_to_sequences(train_clean_cat)\n",
        "test_clean_cat = tokenizer.texts_to_sequences(test_clean_cat)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k63o6PycLga-",
        "outputId": "b2b072fc-27b5-49c1-c135-7e982c9acf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "x_train_clean_cat = sequence.pad_sequences(train_clean_cat, maxlen = max_length, padding='post')\n",
        "x_train_clean_cat.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf2mOXtWLgbA",
        "outputId": "aa4817a4-f266-4917-c4e3-e1f6f5c3d75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test data\n",
        "x_test_clean_cat = sequence.pad_sequences(test_clean_cat, maxlen = max_length, padding='post')\n",
        "x_test_clean_cat.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2VJILITLgbC"
      },
      "source": [
        "**clean_sub_cat**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9R5JLq4LgbD",
        "outputId": "0082c4ac-e1a6-4290-f0bc-50f78bfa5498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_df.clean_subcategories.values.tolist()))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YVUSKSrLgbH"
      },
      "source": [
        "train_clean_sub_cat = train_df.clean_subcategories.values.tolist()\n",
        "test_clean_sub_cat = test_df.clean_subcategories.values.tolist()\n",
        "max_length = 1#len(max(train_clean_sub_cat, key=len).split(' '))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeC04FD1LgbJ"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_clean_sub_cat)\n",
        "train_clean_sub_cat = tokenizer.texts_to_sequences(train_clean_sub_cat)\n",
        "test_clean_sub_cat = tokenizer.texts_to_sequences(test_clean_sub_cat)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTqvQVldLgbL",
        "outputId": "6d5721e3-bf0c-4f6e-c166-63377d679f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "x_train_clean_sub_cat = sequence.pad_sequences(train_clean_sub_cat, maxlen = max_length, padding='post')\n",
        "x_train_clean_sub_cat.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJC9VlrALgbN",
        "outputId": "cd1be573-1b22-4241-c8a1-22fdd4a1aba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test data\n",
        "x_test_clean_sub_cat = sequence.pad_sequences(test_clean_sub_cat, maxlen = max_length, padding='post')\n",
        "x_test_clean_sub_cat.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TwIj4pCLgbP"
      },
      "source": [
        "**Teacher_prefix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7J1qdEdLgbP",
        "outputId": "b5418c70-327e-4913-ecb7-c4ac8a1a3d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(train_df.teacher_prefix.values.tolist()))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_uIuJBwLgbR"
      },
      "source": [
        "train_teacher_prefix = train_df.teacher_prefix.values.tolist()\n",
        "test_teacher_prefix = test_df.teacher_prefix.values.tolist()\n",
        "max_length = 1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cw6fOklLgbT"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_teacher_prefix)\n",
        "train_teacher_prefix = tokenizer.texts_to_sequences(train_teacher_prefix)\n",
        "test_teacher_prefix = tokenizer.texts_to_sequences(test_teacher_prefix)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea5MyTvqLgbX",
        "outputId": "038f9f5d-7bb1-492f-c2f0-1d5abe34db81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "x_train_teacher_prefix = sequence.pad_sequences(train_teacher_prefix, maxlen = max_length, padding='post')\n",
        "x_train_teacher_prefix.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pIHrXoFLgbZ",
        "outputId": "d2971335-82f4-43e1-8a69-ee40b4ca0d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train data\n",
        "x_test_teacher_prefix = sequence.pad_sequences(test_teacher_prefix, maxlen = max_length, padding='post')\n",
        "x_test_teacher_prefix.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OycPw83jLgbb"
      },
      "source": [
        "**Numerical Featurization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG51CWPKLgbc"
      },
      "source": [
        "x_train_previously_posted_projects = train_df['teacher_number_of_previously_posted_projects']#train_df.teacher_number_of_previously_posted_projects.values"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RMmQPlxLgbe"
      },
      "source": [
        "x_test_previously_posted_projects = test_df['teacher_number_of_previously_posted_projects']#test_df.teacher_number_of_previously_posted_projects.values"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xyO0HeVLgbj"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0gxVSYeLgbm"
      },
      "source": [
        "# https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
        "def auroc(y_true, y_pred):\n",
        "    # print(y_true, y_pred)\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ttYsX0PgLgbp",
        "outputId": "fae430ee-da3c-4502-8d7d-61fd832fdea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#input 1\n",
        "input_1 = Input(shape=(328,))\n",
        "x1 =Embedding(vocab_size, 300, weights=[embedding_vectors], input_length=x_train_text.shape[1], trainable=False)(input_1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "x1 = LSTM(64,return_sequences=True)(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "#input 2\n",
        "input_2 = Input(shape=(1,))\n",
        "x2 = Embedding(input_dim= 52, output_dim= 2)(input_2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "#input 3\n",
        "input_3 = Input(shape=(1,))\n",
        "x3 = Embedding(input_dim = 5, output_dim= 2)(input_3)\n",
        "x3 = Flatten()(x3)\n",
        "\n",
        "#input 4\n",
        "input_4 = Input(shape=(1,))\n",
        "x4 = Embedding(input_dim=52,output_dim= 2)(input_4)\n",
        "x4 = Flatten()(x4)\n",
        "\n",
        "#input 5\n",
        "input_5 = Input(shape=(1,))\n",
        "x5 = Embedding(input_dim= 396, output_dim= 64)(input_5)\n",
        "x5 = Flatten()(x5)\n",
        "\n",
        "#input 6\n",
        "input_6 = Input(shape=(1,))\n",
        "x6 = Embedding(input_dim= 6,output_dim= 4)(input_6)\n",
        "x6 = Flatten()(x6)\n",
        "\n",
        "#input 7\n",
        "input_7 = Input(shape=(1,))\n",
        "x7 = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input_7)\n",
        "\n",
        "#merging all the inputs \n",
        "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
        "#x = BatchNormalization()(concat)\n",
        "\n",
        "x = Dense(64, activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "# model with all the inputs\n",
        "model = Model([input_1, input_2, input_3, input_4, input_5, input_6, input_7], output)\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0006,decay = 1e-4), metrics=[auroc])\n",
        "print(model.summary())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 328)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 328, 300)     14726100    input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 328, 300)     0           embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_19 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 328, 64)      93440       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 1, 2)         104         input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_14 (Embedding)        (None, 1, 2)         10          input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_15 (Embedding)        (None, 1, 2)         104         input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 1, 64)        25344       input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 1, 4)         24          input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 20992)        0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 2)            0           embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 2)            0           embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_15 (Flatten)            (None, 2)            0           embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 64)           0           embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_17 (Flatten)            (None, 4)            0           embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 32)           64          input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 21098)        0           flatten_12[0][0]                 \n",
            "                                                                 flatten_13[0][0]                 \n",
            "                                                                 flatten_14[0][0]                 \n",
            "                                                                 flatten_15[0][0]                 \n",
            "                                                                 flatten_16[0][0]                 \n",
            "                                                                 flatten_17[0][0]                 \n",
            "                                                                 dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 64)           1350336     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 64)           0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 32)           2080        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32)           0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32)           128         dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 16)           528         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 16)           0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 2)            34          dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 16,198,296\n",
            "Trainable params: 1,472,132\n",
            "Non-trainable params: 14,726,164\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQqHUva2Lgbr"
      },
      "source": [
        "y_train = train_df.project_is_approved.values.tolist()\n",
        "y_test = test_df.project_is_approved.values.tolist()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HUAAh4XSLgbv"
      },
      "source": [
        "x_train =  [x_train_text, x_train_sch_state, x_train_proj_grade, x_train_clean_cat, x_train_clean_sub_cat, x_train_teacher_prefix, x_train_previously_posted_projects]\n",
        "x_test = [x_test_text, x_test_sch_state, x_test_proj_grade, x_test_clean_cat, x_test_clean_sub_cat, x_test_teacher_prefix, x_test_previously_posted_projects]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSXc2yzLLgbx",
        "outputId": "4aaab6dc-d743-4447-f63d-da1ab0a2e7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "filepath = '/content/drive/My Drive/LSTM_ASST/weight_model1'\n",
        "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint,tensorboard] \n",
        "model.fit(x_train, y_train, epochs=10,verbose=1,batch_size=128, callbacks =callbacks_list)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  2/598 [..............................] - ETA: 1:04 - loss: 0.9281 - auroc: 0.5073WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0470s vs `on_train_batch_end` time: 0.1676s). Check your callbacks.\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.5247 - auroc: 0.5533WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.5247 - auroc: 0.5533\n",
            "Epoch 2/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4424 - auroc: 0.6527WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.4424 - auroc: 0.6528\n",
            "Epoch 3/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4191 - auroc: 0.6899WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.4190 - auroc: 0.6901\n",
            "Epoch 4/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4080 - auroc: 0.7066WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.4080 - auroc: 0.7066\n",
            "Epoch 5/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3999 - auroc: 0.7220WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.3999 - auroc: 0.7220\n",
            "Epoch 6/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3942 - auroc: 0.7322WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.3942 - auroc: 0.7322\n",
            "Epoch 7/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3889 - auroc: 0.7412WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.3890 - auroc: 0.7412\n",
            "Epoch 8/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3854 - auroc: 0.7477WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.3854 - auroc: 0.7477\n",
            "Epoch 9/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3807 - auroc: 0.7580WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.3807 - auroc: 0.7580\n",
            "Epoch 10/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3752 - auroc: 0.7693WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 0.3752 - auroc: 0.7693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f46244c05f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gCP0dxpYLgb1",
        "outputId": "ffdb5123-29e6-4397-9a24-e9b373aef26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Testing model-1\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Train AUC:\",roc_auc_score(y_train,y_train_pred))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train AUC: 0.806198949773304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LQAsoHWLgb2",
        "outputId": "e6c57783-d15b-4e1a-dfb2-b7866f9b9362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Test AUC:\",roc_auc_score(y_test,y_test_pred))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test AUC: 0.7460811787225307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ROQwoVZLgb4"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETdORb1WLgb6"
      },
      "source": [
        "# Save to file in the current working directory\n",
        "def saveModel(filename, model):\n",
        "    try:\n",
        "        import cPickle as pickle\n",
        "\n",
        "    except ImportError:\n",
        "        import pickle\n",
        "\n",
        "    with open(filename, 'wb') as fp:\n",
        "        pickle.dump(model, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    return"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHOXEcJpLgb7"
      },
      "source": [
        "# Load from file\n",
        "def getModel(pkl_filename):\n",
        "    with open(pkl_filename, 'rb') as file:\n",
        "        pickle_model = pickle.load(file)\n",
        "    return pickle_model"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nT6SC9hLgb-"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cot41KvoLgb_"
      },
      "source": [
        "x_train_essay_text = train_df.essay.values.tolist()\n",
        "x_test_essay_text = test_df.essay.values.tolist()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHEvLioOLgcB"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=10, max_features=10000)\n",
        "vectorizer.fit(x_train_essay_text) \n",
        "x_train_tfidf  = vectorizer.transform(x_train_essay_text)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy5kFUdMLgcD",
        "outputId": "e3be5e0f-9a8e-4a9c-f27d-90947629cb1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# box plot to decide the threshold\n",
        "plt.boxplot(vectorizer.idf_)\n",
        "plt.ylabel(\"IDF Value\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'IDF Value')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcdc2I2_LgcE",
        "outputId": "303da786-4857-4069-f8e3-163fb9eb4268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# sortedDiff =np.sort(diff)\n",
        "for i in range (0,101,10):\n",
        "    p = np.percentile(vectorizer.idf_, i)\n",
        "    print(str(i)+\" Percentile: \"+ str(p))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Percentile: 1.0077317773707817\n",
            "10 Percentile: 4.961189206264439\n",
            "20 Percentile: 5.876176147118889\n",
            "30 Percentile: 6.59925919512169\n",
            "40 Percentile: 7.108907655714666\n",
            "50 Percentile: 7.5442257269725115\n",
            "60 Percentile: 7.887997266075336\n",
            "70 Percentile: 8.201654824930378\n",
            "80 Percentile: 8.50703647448156\n",
            "90 Percentile: 8.7789701899652\n",
            "100 Percentile: 9.846810819966556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYtuvRUtLgcG"
      },
      "source": [
        "<p>After 70th percentile idf value nearly remain same. </p>\n",
        "    -min_threshold = 20th percentile<br>\n",
        "    -max_threshold = 80th percentile<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-5dy6BxLgcG",
        "outputId": "b8766e15-29a2-4703-b34e-d45e53b4c858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "min_threshold = 3 # np.percentile(vectorizer.idf_, 20)\n",
        "max_threshold = np.percentile(vectorizer.idf_, 90)\n",
        "print(min_threshold, max_threshold)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 8.7789701899652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LNOamh_LgcI"
      },
      "source": [
        "feat = vectorizer.get_feature_names()\n",
        "idf_val = vectorizer.idf_\n",
        "len(feat), len(idf_val)\n",
        "feat_idf_dict = dict(zip(feat, idf_val))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f-htJ_LgcK",
        "outputId": "80d0333e-b443-4eef-94e5-cfcceebdc2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# new_data = {k: v for k, v in feat_idf_dict.iteritems() if min_threshold < v[0] < max_threshold}\n",
        "for k  in list(feat_idf_dict.keys()):\n",
        "    # removing low and high idf features\n",
        "    if (min_threshold >= feat_idf_dict[k]) or (feat_idf_dict[k] >= max_threshold):\n",
        "        feat_idf_dict.pop(k)\n",
        "\n",
        "len(feat_idf_dict)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42LznkR4LgcM"
      },
      "source": [
        "# removing low and high idf words from dataset\n",
        "def get_filtered_text(text_dataset):\n",
        "    \n",
        "    filtered_text = []\n",
        "    \n",
        "    for text in tqdm(text_dataset):\n",
        "        resultwords  = [word for word in text.split() if word.lower() in list(feat_idf_dict.keys())]\n",
        "        result = ' '.join(resultwords)\n",
        "        filtered_text.append(result)\n",
        "    \n",
        "    return filtered_text"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpNgTYBWoVoS"
      },
      "source": [
        "x_train_essay_text_filtered = get_filtered_text(x_train_essay_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_6OD2Bv4GY"
      },
      "source": [
        "saveModel(\"/content/drive/My Drive/LSTM_ASST/x_train_tfidf_filter.pkl\", x_train_essay_text_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1s_yEraEXV9",
        "outputId": "49080e43-f3e8-4217-c510-e9275da25a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test_essay_text_filtered = get_filtered_text(x_test_essay_text)\n",
        "\n",
        "saveModel(\"/content/drive/My Drive/LSTM_ASST/x_test_tfidf_filter.pkl\", x_test_essay_text_filtered)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32775/32775 [12:33<00:00, 43.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epdZP4fJLgcO"
      },
      "source": [
        "x_train_essay_text_filtered = getModel(\"/content/drive/My Drive/LSTM_ASST/x_train_tfidf_filter.pkl\")\n",
        "x_test_essay_text_filtered = getModel(\"/content/drive/My Drive/LSTM_ASST/x_test_tfidf_filter.pkl\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tarmSUnQLgcP",
        "outputId": "6b67e09f-2983-411c-a6f9-5c6dbb4d13a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tokenizing \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train_essay_text_filtered)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(len(t.word_index))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5LuKKLGLgcS"
      },
      "source": [
        "# load embedding as a dict\n",
        "def load_embedding(filename):\n",
        "\n",
        "    # load embedding into memory, skip first line\n",
        "    file = open(filename, 'r')\n",
        "    lines = file.readlines()[1:]\n",
        "    \n",
        "    file.close()\n",
        "    # create a map of words to vectors\n",
        "    embedding = dict()\n",
        "    for line in lines:\n",
        "        \n",
        "        parts = line.split()\n",
        "        # key is string word, value is numpy array for vector\n",
        "        embedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "    return embedding\n",
        "\n",
        "# create a weight matrix for the Embedding layer from a loaded embedding\n",
        "def get_weight_matrix(embedding, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, 300))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = embedding.get(word)\n",
        "    return weight_matrix\n",
        "\n",
        "# load embedding from file\n",
        "raw_embedding = load_embedding('glove.6B.300d.txt')\n",
        "\n",
        "# get vectors in the right order\n",
        "embedding_vectors = get_weight_matrix(raw_embedding, t.word_index)\n",
        "where_are_NaNs = np.isnan(embedding_vectors)\n",
        "embedding_vectors[where_are_NaNs] = 0"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d2ktJE6LgcU",
        "outputId": "5abc1f44-0464-46c8-d3b8-73c4ad6ac93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train\n",
        "# enocde it to sequences\n",
        "encoded_docs = t.texts_to_sequences(x_train_essay_text_filtered)\n",
        "max_length = len(max(x_train_essay_text_filtered, key=len).split(' '))\n",
        "x_train_text_M2 = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_train_text_M2.shape\n",
        "\n",
        "# Test\n",
        "encoded_docs = t.texts_to_sequences(x_test_essay_text_filtered)\n",
        "x_test_text_M2 = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_test_text_M2.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 216)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCm0knKULgcV",
        "outputId": "70c6e795-705c-41a7-8904-8187182cde10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_text_M2.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 216)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knewwD2HLgcX"
      },
      "source": [
        "# https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
        "def auroc(y_true, y_pred):\n",
        "    # print(y_true, y_pred)\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wgJ7gKOaLgcZ",
        "outputId": "f4c69117-0023-489d-a8da-2fc29444401e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#input 1\n",
        "input_1 = Input(shape=(216,))\n",
        "x1 =Embedding(vocab_size, 300, weights=[embedding_vectors], input_length=x_train_text_M2.shape[1], trainable=False)(input_1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "x1 = LSTM(128,return_sequences=True)(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "#input 2\n",
        "input_2 = Input(shape=(1,))\n",
        "x2 = Embedding(input_dim= 52, output_dim= 2)(input_2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "#input 3\n",
        "input_3 = Input(shape=(1,))\n",
        "x3 = Embedding(input_dim = 5, output_dim= 2)(input_3)\n",
        "x3 = Flatten()(x3)\n",
        "\n",
        "#input 4\n",
        "input_4 = Input(shape=(1,))\n",
        "x4 = Embedding(input_dim=52,output_dim= 2)(input_4)\n",
        "x4 = Flatten()(x4)\n",
        "\n",
        "#input 5\n",
        "input_5 = Input(shape=(1,))\n",
        "x5 = Embedding(input_dim= 396, output_dim= 64)(input_5)\n",
        "x5 = Flatten()(x5)\n",
        "\n",
        "#input 6\n",
        "input_6 = Input(shape=(1,))\n",
        "x6 = Embedding(input_dim= 6,output_dim= 4)(input_6)\n",
        "x6 = Flatten()(x6)\n",
        "\n",
        "#input 7\n",
        "input_7 = Input(shape=(1,))\n",
        "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input_7)\n",
        "\n",
        "#merging all the inputs \n",
        "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
        "#x = BatchNormalization()(concat)\n",
        "\n",
        "x = Dense(64, activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "# model with all the inputs\n",
        "model = Model([input_1, input_2, input_3, input_4, input_5, input_6, input_7], output)\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0006,decay = 1e-4), metrics=[auroc])\n",
        "print(model.summary())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 216)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 216, 300)     2649600     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 216, 300)     0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 216, 128)     219648      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 1, 2)         104         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 1, 2)         10          input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 1, 2)         104         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 1, 64)        25344       input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 1, 4)         24          input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 27648)        0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 2)            0           embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 2)            0           embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 2)            0           embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 64)           0           embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 4)            0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           32          input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 27738)        0           flatten_6[0][0]                  \n",
            "                                                                 flatten_7[0][0]                  \n",
            "                                                                 flatten_8[0][0]                  \n",
            "                                                                 flatten_9[0][0]                  \n",
            "                                                                 flatten_10[0][0]                 \n",
            "                                                                 flatten_11[0][0]                 \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 64)           1775296     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 32)           2080        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32)           128         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 16)           528         batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16)           0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            34          dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,672,932\n",
            "Trainable params: 2,023,268\n",
            "Non-trainable params: 2,649,664\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyCegdZrLgcb"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = train_df.project_is_approved.values.tolist()\n",
        "y_test = test_df.project_is_approved.values.tolist()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHiI32CLgce"
      },
      "source": [
        "x_train =  [x_train_text_M2, x_train_sch_state, x_train_proj_grade, x_train_clean_cat, x_train_clean_sub_cat, x_train_teacher_prefix, x_train_previously_posted_projects]\n",
        "x_test = [x_test_text_M2, x_test_sch_state, x_test_proj_grade, x_test_clean_cat, x_test_clean_sub_cat, x_test_teacher_prefix, x_test_previously_posted_projects]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l1CRQHmNLgch",
        "outputId": "ca38ef27-9ea2-4104-b073-c68925e7091b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
        "filepath = \"/content/drive/My Drive/LSTM_ASST/weight_model2.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint,tensorboard]\n",
        "model.fit(x_train, y_train, epochs=20,verbose=1,batch_size=128, callbacks =callbacks_list)\n",
        "model.save('dc_model2.h5')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  2/598 [..............................] - ETA: 1:35 - loss: 1.0820 - auroc: 0.5159WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0922s vs `on_train_batch_end` time: 0.1942s). Check your callbacks.\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.5921 - auroc: 0.5221WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.5921 - auroc: 0.5221\n",
            "Epoch 2/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4837 - auroc: 0.5595WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4837 - auroc: 0.5595\n",
            "Epoch 3/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4499 - auroc: 0.6094WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4499 - auroc: 0.6094\n",
            "Epoch 4/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4329 - auroc: 0.6485WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4329 - auroc: 0.6485\n",
            "Epoch 5/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4218 - auroc: 0.6725WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4218 - auroc: 0.6725\n",
            "Epoch 6/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4146 - auroc: 0.6861WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4146 - auroc: 0.6861\n",
            "Epoch 7/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4098 - auroc: 0.6953WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4098 - auroc: 0.6953\n",
            "Epoch 8/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4062 - auroc: 0.7032WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4062 - auroc: 0.7032\n",
            "Epoch 9/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4041 - auroc: 0.7086WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4041 - auroc: 0.7086\n",
            "Epoch 10/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4004 - auroc: 0.7156WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.4004 - auroc: 0.7156\n",
            "Epoch 11/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3971 - auroc: 0.7230WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3971 - auroc: 0.7230\n",
            "Epoch 12/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3951 - auroc: 0.7295WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3951 - auroc: 0.7295\n",
            "Epoch 13/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3925 - auroc: 0.7353WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3925 - auroc: 0.7353\n",
            "Epoch 14/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3911 - auroc: 0.7403WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3911 - auroc: 0.7403\n",
            "Epoch 15/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3876 - auroc: 0.7469WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3876 - auroc: 0.7469\n",
            "Epoch 16/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3851 - auroc: 0.7540WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3851 - auroc: 0.7540\n",
            "Epoch 17/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3809 - auroc: 0.7636WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3809 - auroc: 0.7636\n",
            "Epoch 18/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3774 - auroc: 0.7733WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3774 - auroc: 0.7733\n",
            "Epoch 19/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3723 - auroc: 0.7828WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3723 - auroc: 0.7828\n",
            "Epoch 20/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3686 - auroc: 0.7919WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 63s 105ms/step - loss: 0.3686 - auroc: 0.7919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7j7jgNsLgck"
      },
      "source": [
        "# https://github.com/keras-team/keras/issues/10104\n",
        "dependencies = {'auroc': auroc}\n",
        "model = load_model(\"dc_model2.h5\", custom_objects=dependencies)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWCGzFCNLgcl",
        "outputId": "4a746939-12bd-4cef-f4f2-78ea47507057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Testing model-2\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Train AUC:\",roc_auc_score(y_train,y_train_pred))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train AUC: 0.8477791488455313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgaUj30ELgcn",
        "outputId": "42e7c9ff-ab85-4736-a296-7182d23580a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Test AUC:\",roc_auc_score(y_test,y_test_pred))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test AUC: 0.71584461681013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS10IsIJLgco"
      },
      "source": [
        "# Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKfoiEXMLgcp",
        "outputId": "c0992303-7a98-4e67-97af-d7e8ffffffaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# http://flovv.github.io/Embeddings_with_keras_part2/\n",
        "# school state\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_sch_state = token.fit_transform(train_df.school_state)\n",
        "x_test_sch_state = token.transform(test_df.school_state)\n",
        "print(x_train_sch_state.shape, x_test_sch_state.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 51) (32775, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiTy627MLgct",
        "outputId": "29b6e0b0-e8eb-40f4-b5d9-232b237dde4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# proj_grade\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_proj_grade = token.fit_transform(train_df.project_grade_category)\n",
        "x_test_proj_grade = token.transform(test_df.project_grade_category)\n",
        "print(x_train_proj_grade.shape, x_test_proj_grade.shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 4) (32775, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvh4MU4GLgcv",
        "outputId": "9568a034-d510-41d4-827d-33ffbbce7c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# clean_cat\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_clean_cat = token.fit_transform(train_df.clean_categories)\n",
        "x_test_clean_cat = token.transform(test_df.clean_categories)\n",
        "print(x_train_clean_cat.shape, x_test_clean_cat.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 9) (32775, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9J5d6WmLgcw",
        "outputId": "08b558d8-d382-4ed1-e556-08b57deaf18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# x_train_clean_sub_cat\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_clean_sub_cat = token.fit_transform(train_df.clean_subcategories)\n",
        "x_test_clean_sub_cat = token.transform(test_df.clean_subcategories)\n",
        "print(x_train_clean_sub_cat.shape, x_test_clean_sub_cat.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 30) (32775, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnDbdrWOLgc0",
        "outputId": "4d722a20-db83-4a40-c36d-5dfdf604e4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# x_train_teacher_prefix\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_teacher_prefix = token.fit_transform(train_df.teacher_prefix)\n",
        "x_test_teacher_prefix = token.transform(test_df.teacher_prefix)\n",
        "print(x_train_teacher_prefix.shape, x_test_teacher_prefix.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 5) (32775, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfuaoYy9Lgc2",
        "outputId": "2064e936-9889-4ab8-a685-9232ed6d24bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_previously_posted_projects = train_df.teacher_number_of_previously_posted_projects.values\n",
        "x_train_previously_posted_projects = x_train_previously_posted_projects.reshape(76473, 1)\n",
        "#x_train_previously_posted_projects.shape\n",
        "x_test_previously_posted_projects = test_df.teacher_number_of_previously_posted_projects.values\n",
        "x_test_previously_posted_projects = x_test_previously_posted_projects.reshape(32775, 1)\n",
        "print(x_train_previously_posted_projects.shape, x_test_previously_posted_projects.shape) "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 1) (32775, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9ecJLZ4Lgc3"
      },
      "source": [
        "### input_1\n",
        "x_train_1 =  x_train_text\n",
        "x_test_1 =   x_test_text"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZNFB6CTLgc4",
        "outputId": "133c576a-fca9-41c8-945d-dcc00a28ca2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### input 2\n",
        "x_train_2 = hstack((x_train_sch_state, x_train_proj_grade, x_train_clean_cat, x_train_clean_sub_cat, x_train_teacher_prefix, x_train_previously_posted_projects)).todense()\n",
        "x_train_2 = np.array(x_train_2).reshape(x_train_2.shape[0],x_train_2.shape[1],1)\n",
        "\n",
        "x_test_2 = hstack((x_test_sch_state, x_test_proj_grade, x_test_clean_cat, x_test_clean_sub_cat, x_test_teacher_prefix, x_test_previously_posted_projects)).todense()\n",
        "x_test_2 = np.array(x_test_2).reshape(x_test_2.shape[0],x_test_2.shape[1],1)\n",
        "\n",
        "x_train_2.shape, x_test_2.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((76473, 100, 1), (32775, 100, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K0yqEJrLgc5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AUCPGCQFLgc6",
        "outputId": "1fde5b99-d23c-4646-a08a-663e79c061ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "# input 1\n",
        "input_1 = Input(shape=(328,))\n",
        "x1 =Embedding(vocab_size,300, weights=[embedding_vectors], input_length=x_train_text.shape[1], trainable=False)(input_1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "x1 = LSTM(64,return_sequences=True)(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "# input 2\n",
        "input_2 = Input(shape=(100,1))\n",
        "x2 = Conv1D(filters=64,kernel_size=3, strides=1)(input_2)\n",
        "x2 = Conv1D(filters=32,kernel_size=3, strides=1)(x2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "\n",
        "# merging both the inputs\n",
        "concat = concatenate([x1,x2])\n",
        "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(2, activation = 'softmax')(x)\n",
        " \n",
        "# create model with two inputs\n",
        "model = Model([input_1,input_2], output)\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0006,decay = 1e-4), metrics=[auroc])\n",
        "print(model.summary())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 328)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 328, 300)     14726100    input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           [(None, 100, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 328, 300)     0           embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 98, 64)       256         input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 328, 64)      93440       dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 96, 32)       6176        conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_18 (Flatten)            (None, 20992)        0           lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_19 (Flatten)            (None, 3072)         0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 24064)        0           flatten_18[0][0]                 \n",
            "                                                                 flatten_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 64)           1540160     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 64)           0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 32)           2080        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32)           0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32)           128         dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 16)           528         batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16)           0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 2)            34          dropout_15[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 16,368,902\n",
            "Trainable params: 1,642,738\n",
            "Non-trainable params: 14,726,164\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT-VDo6eLgc8"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = train_df.project_is_approved.values.tolist()\n",
        "y_test = test_df.project_is_approved.values.tolist()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W585HazLgc-"
      },
      "source": [
        "x_train = x_train_1, x_train_2\n",
        "x_test  = x_test_1, x_test_2"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOx6ZJqYLgc_",
        "outputId": "1dab0216-4434-4461-dbf9-85e983a1ea3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "filepath = \"/content/drive/My Drive/LSTM_ASST/weight_model3.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint,tensorboard] \n",
        "model.fit(x_train, y_train, epochs=10,verbose=1,batch_size=128, callbacks =callbacks_list)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  2/598 [..............................] - ETA: 1:03 - loss: 1.0245 - auroc: 0.4765WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0501s vs `on_train_batch_end` time: 0.1625s). Check your callbacks.\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.5251 - auroc: 0.5702WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 37ms/step - loss: 0.5251 - auroc: 0.5702\n",
            "Epoch 2/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4411 - auroc: 0.6581WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 37ms/step - loss: 0.4410 - auroc: 0.6583\n",
            "Epoch 3/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4187 - auroc: 0.6939WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.4187 - auroc: 0.6939\n",
            "Epoch 4/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4081 - auroc: 0.7098WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.4080 - auroc: 0.7100\n",
            "Epoch 5/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4026 - auroc: 0.7216WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.4026 - auroc: 0.7216\n",
            "Epoch 6/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3972 - auroc: 0.7302WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.3972 - auroc: 0.7303\n",
            "Epoch 7/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3938 - auroc: 0.7398WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.3937 - auroc: 0.7398\n",
            "Epoch 8/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3923 - auroc: 0.7468WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.3922 - auroc: 0.7468\n",
            "Epoch 9/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3900 - auroc: 0.7570WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.3899 - auroc: 0.7572\n",
            "Epoch 10/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3872 - auroc: 0.7651WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 22s 36ms/step - loss: 0.3872 - auroc: 0.7653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f461ac2bd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y_BOOD3LgdB",
        "outputId": "14b2ed73-353a-4d5f-e3f5-1444b936a039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "### Testing model-3\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Train AUC:\",roc_auc_score(y_train,y_train_pred))\n",
        "\n",
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Test AUC:\",roc_auc_score(y_test,y_test_pred))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train AUC: 0.8126248871395355\n",
            "Test AUC: 0.7449460499757181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfDy1EWjLgdE"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLAdmoCQLgdE",
        "outputId": "429ca324-f46d-43a1-fbdd-43a3bbf4dc4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from prettytable import PrettyTable    \n",
        "x = PrettyTable()\n",
        "x.field_names = [\"Architecture\", \"Train AUC\", \"Test AUC\"]\n",
        "x.add_row([\"Model-1\", \"0.8061989\", \"0.7460811\"])\n",
        "x.add_row([\"Model-2\", \"0.8477791\", \" 0.71584\"])\n",
        "x.add_row([\"Model-3\", \"0.8126248\", \"0.744946\"])\n",
        "print(x)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----------+-----------+\n",
            "| Architecture | Train AUC |  Test AUC |\n",
            "+--------------+-----------+-----------+\n",
            "|   Model-1    | 0.8061989 | 0.7460811 |\n",
            "|   Model-2    | 0.8477791 |   0.71584 |\n",
            "|   Model-3    | 0.8126248 |  0.744946 |\n",
            "+--------------+-----------+-----------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}